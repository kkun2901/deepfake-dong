# 현재 컴퓨터 사양 분석 및 튜닝 가능 여부

## 📊 현재 사양 분석

### 확인된 사양:
- **CPU**: 2.89GHz (사용률 12%)
- **RAM**: 16GB (9.1GB 사용 중, 58% 사용률)
- **GPU**: Intel UHD Graphics (통합 그래픽)
- **디스크**: SSD (C:), HDD (D:)

## ✅ 튜닝 가능 여부

### 가능합니다! 하지만 몇 가지 제약사항이 있습니다.

## ⚠️ 제약사항

### 1. GPU 학습 불가능
- **Intel UHD Graphics**: CUDA를 지원하지 않음
- **결과**: CPU로만 학습 가능 (GPU 옵션 사용 불가)

### 2. CPU 학습 속도
- **예상 시간**: 매우 느림 (8-15시간)
- **권장**: 밤에 돌려두거나 작은 데이터셋 사용

### 3. 메모리
- **현재 사용**: 9.1GB / 16GB (58%)
- **여유 공간**: 약 6.6GB
- **결론**: 충분함 (1-2GB 데이터셋 학습 가능)

## 🎯 권장 설정

### 1. 데이터셋 크기
- **권장**: 500MB ~ 1GB (작은 데이터셋)
- **이유**: CPU 학습이 느리므로 작은 데이터셋으로 빠르게 테스트

### 2. 배치 크기
- **권장**: 16 또는 32
- **이유**: 메모리 여유가 있지만 CPU 학습이므로 작은 배치가 안정적

### 3. 에포크 수
- **권장**: 10-15 에포크 (처음 테스트)
- **이유**: 시간 절약, 결과 확인 후 필요시 증가

### 4. 학습 시간
- **500MB 데이터셋**: 약 3-5시간 (CPU)
- **1GB 데이터셋**: 약 6-10시간 (CPU)
- **1.5GB 데이터셋**: 약 9-15시간 (CPU)

## 💻 최적화 팁

### 1. CPU 스레드 수 조정
```python
# config.py에서 이미 설정됨
TORCH_NUM_THREADS = 4  # CPU 코어 수에 맞게 조정 가능
```

### 2. 배치 크기 조정
```bash
# 메모리 여유가 있으므로 32는 가능
python train_mesonet.py \
    --data-dir dataset/train \
    --val-dir dataset/val \
    --batch-size 32 \
    --epochs 10
```

### 3. 얼굴 crop 비활성화 (선택)
```bash
# 더 빠른 학습을 위해 (성능 약간 하락 가능)
python train_mesonet.py \
    --data-dir dataset/train \
    --val-dir dataset/val \
    --no-face-crop \
    --batch-size 32 \
    --epochs 10
```

### 4. SSD에 데이터셋 저장
- **권장**: C: 드라이브 (SSD)에 데이터셋 저장
- **이유**: 더 빠른 읽기 속도

## 📋 실행 예시

### 작은 데이터셋으로 빠른 테스트:
```bash
cd backend

# 500MB 데이터셋으로 10 에포크 테스트
python train_mesonet.py \
    --data-dir dataset_small/train \
    --val-dir dataset_small/val \
    --epochs 10 \
    --batch-size 32
```

**예상 시간**: 약 3-5시간

### 본격 학습 (1GB 데이터셋):
```bash
python train_mesonet.py \
    --data-dir dataset/train \
    --val-dir dataset/val \
    --epochs 20 \
    --batch-size 32
```

**예상 시간**: 약 6-10시간 (밤에 돌려두기 권장)

## ⚡ 성능 개선 옵션

### 1. 외부 GPU 사용 (선택사항)
- **Google Colab**: 무료 GPU 제공
- **Kaggle Notebooks**: 무료 GPU 제공
- **로컬 학습 후 가중치만 다운로드**

### 2. 클라우드 학습
- **AWS EC2**: GPU 인스턴스
- **Google Cloud**: GPU 인스턴스
- **Azure**: GPU 인스턴스

### 3. 작은 데이터셋으로 시작
- **500MB 데이터셋**: 빠른 테스트
- **결과 확인 후**: 필요시 더 큰 데이터셋 사용

## ✅ 결론

### 가능합니다!
- ✅ **CPU 학습 가능**: 느리지만 가능
- ✅ **메모리 충분**: 16GB로 1-2GB 데이터셋 학습 가능
- ✅ **디스크 공간**: SSD 사용 권장

### 권장 사항:
1. **작은 데이터셋으로 시작** (500MB-1GB)
2. **밤에 학습 실행** (시간이 오래 걸림)
3. **10 에포크로 테스트** 후 결과 확인
4. **SSD에 데이터셋 저장** (C: 드라이브)

### 예상 시간:
- **500MB 데이터셋**: 3-5시간
- **1GB 데이터셋**: 6-10시간
- **1.5GB 데이터셋**: 9-15시간

**결론**: 현재 사양으로 튜닝 가능하지만, CPU 학습이므로 시간이 오래 걸립니다. 작은 데이터셋으로 시작하는 것을 강력히 권장합니다!



